#   bbrot.py
#                   v2
#
#       2022.07.09

#ライブラリの読み込み
import math
from webbrowser import BackgroundBrowser
from cv2 import DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
from PIL import Image
import sys
sys.path.append('/path/to/dir')
import pyocr
import pyocr.builders

#ウインドウの設定
cv2.namedWindow('template3', cv2.WINDOW_NORMAL)
cv2.moveWindow('template3', 0, 200)
cv2.namedWindow('match BB', cv2.WINDOW_NORMAL)
cv2.moveWindow('match BB', 200, 200)

#色の定義
mazenta = (255, 0, 255)
yellow  = (0, 255, 255)
green   = (0, 255, 0)
darkGreen = (0, 127, 0)
white   = (255, 255, 255)


def process(filename):
    """
    写っているすべてのBB弾の角度を推定

    Parameters
    ----------
    filename : string
        画像ファイル名

    Returns
    -------
        結果をオーバーレイした画像
    """

    image = cv2.imread(filename)
    #画像サイズと推定BB弾寸法（撮影範囲による）
    #撮影対象の大きさ[mm]
    subjectWidthMin = 210   #横方向撮影範囲寸法
    subjectWidthMax = 320
    bbObjectSize = 6        #BB弾の物理寸法
    #BB弾の推定サイズ[pixel]の計算
    bbPixelMin = int(image.shape[1] / subjectWidthMax * bbObjectSize)
    bbPixelMax = int(image.shape[1] / subjectWidthMin * bbObjectSize)
    print('画像サイズ (x:', image.shape[1], 'y:', image.shape[0], ')')
    print('BB弾の大きさ', bbPixelMin, '~', bbPixelMax, 'pix')

    #グレースケール化(OCRで使用)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    #高さを中央付近450pxにクロップ
    w = image.shape[1]
    h = 450     #切り取り画像の縦ピクセル数
    top = (image.shape[0] - h) // 2
    flip = image[top: top + h, 0: w]
    #右から撃っているので、左から右への時系列になるように左右反転
    flip = cv2.flip(flip, 1)                                        # =0:上下反転、>0:左右反転、 <0:上下左右反転
    #コントラスト調整 (テンプレートマッチングで使用)
    scaled = cv2.convertScaleAbs(flip, alpha = 3.5, beta = 0)       #alpha:スケールファクタ1.0〜2.0 beta:加算値
    #ノイズ除去してブロブ検出用の画像を作成
    median = cv2.medianBlur(flip, ksize = 9)                        #ksizeは奇数 円の検出大きさに関わってくる
    #平坦化
    clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (8,8))
    cl1 = clahe.apply(flip)
    #二値化の閾値
    minGray = 0
    maxGray = 255
    #大津の手法　minGrayに大津の閾値が入る
    minGray, threshold = cv2.threshold(median, minGray, maxGray, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

    hw = 350    #表示座標y
    hwd = 140
    winShow(flip, 'flip', (700, hw), (w // 4, h // 4))  #1/4に縮小
    winShow(scaled, 'scaled', (700, hw + hwd), (w // 4, h // 4))
    winShow(median, 'median', (700, hw + hwd + hwd), (w // 4, h // 4))
    winShow(threshold, 'threshold', (700, hw + hwd + hwd + hwd), (w // 4, h // 4))
    winShow(cl1, 'CLAHE', (700, hw + hwd + hwd + hwd + hwd), (w // 4, h // 4))
    print('OHTU threshold = ',minGray)

    #ヒストグラム
    hist1 = cv2.calcHist(flip, channels = [0], mask = None, histSize = [256], ranges = [0,256])
    hist2 = cv2.calcHist(scaled, channels = [0], mask = None, histSize = [256], ranges = [0,256])
    hist3 = cv2.calcHist(cl1, channels = [0], mask = None, histSize = [256], ranges = [0,256])
    '''
    plt.plot(hist1)  #ヒストグラム
    plt.plot(hist2)  #ヒストグラム
    plt.plot(hist3)  #ヒストグラム
    plt.show()
    '''

#############################
    cv2.waitKey(1)
    #円検出
    circles = cv2.HoughCircles(median, cv2.HOUGH_GRADIENT, dp = 1.0, minDist = 200, param1 = 100, param2 = 40, minRadius = bbPixelMin // 2-10, maxRadius = bbPixelMax // 2+20)
    #型変換
    circles = np.uint16(np.around(circles))
    circles = np.squeeze(circles)       #[]をひとつ削除する（サイズが1の次元が全て削除される　(1,16,3)->(16,3)　　）

    #円を描写
    cirImg = flip.copy()
    cirImg = cv2.cvtColor(cirImg, cv2.COLOR_GRAY2BGR)
    for c in circles:
        # 円周を描画する
        cv2.circle(cirImg, (c[0], c[1]), c[2], green, 2)
        # 中心点を描画する
        cv2.drawMarker(cirImg, (c[0], c[1]), green, markerType = cv2.MARKER_CROSS, markerSize = 250, thickness = 2)

    winShow(cirImg, filename + ' hough', (700, 190), (w // 4, h // 4))  #1/4に縮小
    cv2.waitKey(1)

    bbcount2 = len(circles)
    print('Hough circles: ', bbcount2)
    #x位置順にソート
    circles = sorted(circles, key=lambda x: x[0])    #x[0]:x座標
    print(circles)

#############################



    blobs = flip.copy()
    blobs = cv2.cvtColor(blobs, cv2.COLOR_GRAY2BGR)

    #ブロブ検出
    keypoints = blobsDetect(threshold, minGray, maxGray, bbPixelMin, bbPixelMax)

    #ブロブを円形で表示
    blobs = cv2.drawKeypoints(blobs, keypoints, None, green, cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
    #ブロブの個数
    bbcount = len(keypoints)
    print(f'blobs 円の個数: {bbcount}')
    winShow(blobs, filename + ' blob', (700, 190), (w // 4, h // 4))  #1/4に縮小

    ######画像変換の様子だけ見たい時##############
    #cv2.waitKey(1)
    print('brobs')
    #return -1 ################
 

    #ブロブ検出数の判定
    if bbcount < 10:
        print('検出数不足   any key to next')
        cv2.waitKey(0)
        return blobs    #円検出だけの画像

    #途中が抜けた時の処理ーーー未定
    #小さいものの除外 ーーーー未定

    #座標x位置順でソート
    kps = sorted(keypoints, key=lambda kp: kp.pt[0])    #kp.pt[0]:x座標

    bbData = []
    bbnum = 0
    for k in kps:          ###test
        center = (int(k.pt[0]), int(k.pt[1]))
        #ブロブの中心を表示
        cv2.drawMarker(blobs, center, darkGreen, markerType = cv2.MARKER_CROSS, markerSize = 300)
        bbData.append((bbnum, center, int(k.size)))
        bbnum += 1

    #平均サイズ
    sumSize = 0
    for k in kps:
        sumSize = sumSize + k.size
    bbAve = sumSize / bbcount    
    print('BB size ave ={:6.2f}'.format(bbAve))
    index = 0
    for k in kps:
        #小さすぎるものを除外する
        if (k.size > bbAve * 1.05) or (k.size < bbAve * 0.97):
            print('No.', index, 'サイズ不適')
            #データ削除
############################
            
        index += 1


    #BB進行軸線の傾斜角度
    dY = kps[bbcount - 1].pt[1] - kps[0].pt[1]
    dX = kps[bbcount - 1].pt[0] - kps[0].pt[0]
    incAngle = -math.degrees(math.atan(dY / dX))   #下向きをマイナス表示
    print('BB n,(x,y),size', bbData)
    print('inclination angle: {:6.3f}/{:6.1f} = {:6.3f}deg'.format(dY, dX, incAngle))

    




    #### OCR #####   
    ocrLcd(image)
    #周期の入力
    while(1):
        inpt = input('1コマの周期 usec = ')
        if inpt == '':
            continue
        dt = float(inpt)
        if dt > 0:
         break


    #画像へコマ周期、初速、ファイル名を書き込み
    v0 = 0.012 / (dt / 1000000) 
    text = "Circular Blobs:{:2d}  dt:{:5.1f}usec  v0:{:5.1f}m/sec  incline:{:6.3f}deg  ({})".format(len(keypoints), dt, v0, incAngle, filename)
    locate = (int(kps[0].pt[0]), int(kps[0].pt[1] + 100))
    cv2.putText(blobs, text, locate, cv2.FONT_HERSHEY_SIMPLEX, 0.8, white, 1)


    #ブロブ検出結果から作業用画像をクロップする  #########################################
    #x座標
    offsetX = 250
    left = bbData[0][1][0] - offsetX
    if left < 0:
        left = 0
    right = bbData[bbcount - 1][1][0] + offsetX
    if right > blobs.shape[1]:              #(y_size, x_size, color)
        right = blobs.shape[1]
    #y座標
    offsetY = 25
    bby = sorted(bbData, key = lambda x: x[1])    #y座標でソート
    top = bby[0][1][1] - bbData[0][2] - offsetY
    if top < 0:
        top = 0
    bottom = bby[bbcount - 1][1][1]  + bbData[0][2] + offsetY  #(y_size, x_size, color)
    if bottom > blobs.shape[0]:     
        bottom = blobs.shape[0]

    #ブロブ検出＆作業書き込み用画像をクロップ
    d = len(blobs.shape)
    if d <= 2:
        blobs =  blobs[top:bottom, left:right]
    else:
        blobs = blobs[top:bottom, left:right, :]
    #マッチ検出用画像もクロップ
    d = len(scaled.shape)
    if d <= 2:
        scaled =  scaled[top:bottom, left:right]
    else:
        scaled = scaled[top:bottom, left:right, :]
    #median画像もクロップ
    d = len(median.shape)
    if d <= 2:
        median =  median[top:bottom, left:right]
    else:
        median = median[top:bottom, left:right, :]

    cv2.imshow("blobs", blobs) 
    cv2.imshow('scaled', scaled)
    cv2.imshow('median', median)
    cv2.waitKey(1)

    #クロップ後の座標修正
    bbcenter2 = []
    for b in bbData:
        bbcenter2.append((b[1][0] - left, b[1][1] - top))


    #左から数えてtemplate_index目のBB弾を基準とする
    #カメラ撮影光軸中心付近
    templateIndex = bbcount // 2   #//の答えは整数となる

    #基準としたBB弾を切り出してテンプレートとする
    
    tempD = int(kps[templateIndex].size * 0.93)     #周辺の影の部分をマスク
    imgc = crop(scaled, bbcenter2[templateIndex], (tempD, tempD))
    #imgc = crop(median, bbcenter2[templateIndex], (tempD, tempD))###特徴点検出のとき####################################
    template = mask_circle(imgc, tempD)
    #2値化オプション??###
    #ret, template = cv2.threshold(template, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) 

#########特徴点検出用テンプレート（周辺画像までいれて広くしないと特徴点が検出されない）
    template2 = crop(median, bbcenter2[templateIndex],(tempD * 3, tempD * 3))
#####################特徴点検出法


    #検出したBB弾すべてに角度推定を実行する
    print('計算開始')

    result = []
    anglefirst = 999
    for k in range(bbcount):
        point = bbcenter2[k] #BB中心
        #回転角度を解析
        angle = estimate_rot(scaled, template, point, kps[templateIndex].size) #bbcenter[k][2]) ########scaled

        #回転角がひっくり返っている時の処理　ーーー未定


###################
        #特徴点検出法
        #angle2 = contourMatch(median, template2, point, kps[templateIndex].size)
####################


        #回転角度の線を表示
        lineLen = 160 // 2
        rad = math.radians(angle)
        dl = (math.cos(rad) * lineLen, -math.sin(rad) * lineLen)
        pt1 = np.add     (point, dl).astype(np.int16)
        pt2 = np.subtract(point, dl).astype(np.int16)
        cv2.line(blobs, pt1, pt2, mazenta, thickness = 1)
        
        if anglefirst == 999:
            anglefirst = angle
            angleBefore = angle

        #角度の書き込み
        da = angle - angleBefore
        angleTotal = angle - anglefirst
        angleBefore = angle

        textAngle = '{:6.1f}deg'.format(angle)
        cv2.putText(blobs, textAngle, org = (point[0] + 30, point[1] - 60), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.8, color = mazenta, thickness = 1)
        if k >= 1:
            textDa = '({:5.1f})'.format(da)
            cv2.putText(blobs, textDa, org = (point[0] + 65, point[1] - 30), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.8, color = yellow, thickness = 1)

        #回転角の書き込み
        if k > templateIndex:
            try:
                kaiten = 1000000.0 / dt /(k * 360 / angleTotal)
                textRps =  '{:6.1f}rps'.format (kaiten)
                cv2.putText(blobs, textRps, org = (point[0] + 0, point[1] + 90), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.8, color = white, thickness = 1)
                #中心振り分けでの回転数計算
                dk = k - templateIndex
                kaiten2 = 1000000.0 / dt /((dk * 2) * 360 /(angle - result[templateIndex - dk][4]))
                textRps2 =  '{:6.1f}rps'.format (kaiten2)
                cv2.putText(blobs, textRps2, org = (point[0] + 10, point[1] + 108), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.6, color = yellow, thickness = 1)

            except ZeroDivisionError:
                kaiten = 0
        result.append((k, point[0], point[1], bbData[k][2], angle, da, angleTotal))

        cv2.imshow("blobs", blobs) 
#################
        cv2.waitKey(1) ##################### 0: WAIT ###############
##################

    # 結果の表示など
    for i, d in enumerate(result):
        print(*d, sep = ',')
    
    # コマ数と回転角
    for r in result[templateIndex: ]:
        koma = r[0]
        try:
            kaiten = 1000000.0 / dt /(r[0] * 360 / r[6])
        except ZeroDivisionError:
            kaiten = 0    
        print('{:2d}コマ {:6.1f}rps'.format(koma, kaiten))
    return blobs


def blobsDetect(image, minGray, maxGray, bbPixelMin, bbPixelMax):
    """
    ブロブ（かたまり）検出器を設定して検出

    Parameters
    ----------
    image : mat
        検出対象の画像
    minGray : int
    maxGray : int
        二値化の閾値 0 ~ 255
    bbPixelMin : int
    bbPixelMax : int
        BB弾の大きさ px
    
    Returns
    -------
        ブロブ位置座標とサイズ
    """

    #ブロブ（塊）検出器の設定
    params = cv2.SimpleBlobDetector_Params()
    #白のブロブを検出
    params.blobColor = 255      #黒検出したい時は0
     #閾値
    params.minThreshold = minGray
    params.maxThreshold = maxGray
    #塊の大きさ（面積）
    params.filterByArea = True
    shade = 0.95      #影、インク模様の面積分の補正
    params.minArea = bbPixelMin ** 2 * math.pi / 4 * shade      ##小さい円が入りすぎ＃＃＃＃＃＃＃＃＃＃＃
    params.maxArea = bbPixelMax ** 2 * math.pi / 4
    #円形度でフィルタ(凹面concave)
    params.filterByCircularity = True
    params.minCircularity = 0.4   #0〜1 = 4πS/L^2   S:面積(画素数) L:周囲長　　　円形度が高い->1.0
    ###模様が外周にかかって輪郭が切れた時に凹面になるので小さめの値にする
    #凸面フィルタ
    params.filterByConvexity = True
    params.minConvexity = 0.5       #0〜1 = S/C  S:面積　C:凸面の面積（円形から出っぱった分）
    #楕円形フィルタ（形態の伸び　円形=1、直線=0 慣性モーメント）
    params.filterByInertia = True
    params.minInertiaRatio = 0.5
    #検出器を設定
    ver = (cv2.__version__).split('.')
    if int(ver[0]) <= 2:
        #openCV ver.2
        detector = cv2.SimpleBlobDetector(params)
    else:
        #openCV ver.3~
        detector = cv2.SimpleBlobDetector_create(params)  

    #検出器を作動（ブロブを検出する）
    keypoints = detector.detect(image)
    return keypoints


def estimate_rot(image, template, pt, size):
    """
    回転角の推定

    Parameters
    ----------
    image : mat
        推定対象の画像
    template : mat
        テンプレート画像
    pt : [number, number]
        推定対象の中心位置[col,row]
    size : any
        比較するBB画像の直径 px 

    Returns
    -------
    回転角 -180~+180(deg)
    """
    angle = -1
    max = 1
    ext = 10    #周りを少し広く
    cr = crop(image, pt, (size + ext, size + ext ))
    cv2.imshow("match BB", cr)
    (w, h) = template.shape[: : -1] 

    #### whole test #####
    '''
    img2 = image.copy()
    matchResult = cv2.matchTemplate(img2, template, cv2.TM_CCOEFF)
    _, maxVal, _, maxLoc = cv2.minMaxLoc(matchResult)   ###minVal,maxVal,minIndex,maxIndex
    topLeft = maxLoc
    bottomRight = (topLeft[0] + w, topLeft[1] + h)
    cv2.rectangle(img2, topLeft, bottomRight, (255, 0, 255), 3)
    #マッチリザルト
    plt.subplot(121),plt.imshow(matchResult, cmap = 'gray')
    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])
    plt.subplot(122),plt.imshow(img2, cmap = 'gray')
    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])
    plt.show()
    #うまくいかない
    '''
    #######################


    # ぐるぐる回しながら相関が最大となる角度を求める
    denomi = 1      #角度計算のステップ　1度/denomi
    matchAngle = 0
    for i in range(-180 * denomi, 180 * denomi):
        angle = i / denomi
        tp = rot(template, angle)
        matchResult = cv2.matchTemplate(cr, tp, cv2.TM_CCOEFF)
        _, maxVal, _, maxLoc = cv2.minMaxLoc(matchResult)   ###minVal,maxVal,minIndex,maxIndex
        
        if(maxVal > max):
            cr2 = cr.copy()
            matchAngle = angle
            max = maxVal
            if denomi < 3:
                #角度表示
                cv2.putText(tp, str(matchAngle), org = (0, 15), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.4, color = 0, thickness = 1)
                # org は左下の座標
                #マッチ値表示
                cv2.putText(tp, str(int(max)), org = (0, 100), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.4, color = 0, thickness = 1)
                topLeft = maxLoc
                bottomRight = (topLeft[0] + w, topLeft[1] + h)
                cv2.rectangle(cr2, topLeft, bottomRight, (255, 0, 255), 1)
            
                cv2.imshow("match BB", cr2)
                cv2.imshow("template3", tp)
                cv2.waitKey(1)

                #マッチ　類似度のヒートマップ
                #fig, ax = plt.subplots(figsize=(10, 5))
                #im = ax.imshow(matchResult, cmap="jet")
                #plt.show()
            

    print(matchAngle , '° Match value:' ,max)
    return matchAngle



def contourMatch(image, template, pt, size):
    """
    特徴点検出にて角度を求める

    Parameters
    ----------
    image : mat
        BB弾列の画像
    template : mat
        テンプレート画像
    pt : [number, number]
        推定対象の中心位置[col,row]
    size : any
        比較するBB画像の直径 px 

    Returns
    -------
    回転角 -180~+180(deg)#####################
    """

    ext = 200    #周りを少し広く
    cr = crop(image, pt, (size + ext, size + ext ))
    #ret, template = cv2.threshold(template, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    #ret, cr = cv2.threshold(cr, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

    #cv2.imshow("match BB2", template)
    match(template, cr)
    return


def match(img1, img2):
    # 特徴点抽出
    det = cv2.ORB_create()#ORB
    # 各画像の特徴点を取る
    kp1, des1 = det.detectAndCompute(img1, None)
    kp2, des2 = det.detectAndCompute(img2, None)
    
    # 2つの特徴点をマッチさせる
    bf = cv2.BFMatcher(cv2.NORM_HAMMING)#, crossCheck = True)
    #matches = bf.match(des1, des2)
    matches = bf.knnMatch(des1, des2, k = 2)

    # レシオテストを行う
    th = 0.85 #0.60
    good = []
    for m, n in matches:
        if m.distance < n.distance * th:
            good.append([m])

    # 特徴点を同士をつなぐ
    img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None)
    #cv2.imshow('keypoint match', img3)
    #cv2.waitKey(0)

    #変数の形を合わせる　＝　配列の次元と数を揃える
    nu = len(good)
    fromKp = []
    for k in kp1[:nu]:
        fromKp.append([k.pt[0],k.pt[1]])
    fromKp = np.reshape(fromKp, (-1, 1, 2))

    toKp = []
    for k in kp2[:nu]:
        toKp.append([k.pt[0],k.pt[1]])
    toKp   = np.reshape(toKp, (-1, 1, 2))

    aA, inliers = cv2.estimateAffinePartial2D(fromKp, toKp)     #2つの変数の数が合わないとダメなよう

    #平行移動量
    mM = aA[:2, :2]
    t = aA[:, 2]
    #回転角度
    degree = np.rad2deg(-np.arctan2(aA[0, 1], aA[0, 0]))
    print('特徴点　回転角度＝' , degree)
    #print(' M', mM, 't', t)

    textDa = '{:6.2f}deg'.format(degree)
    cv2.putText(img3, textDa, org = (160, 250), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1.0, color = white, thickness = 1)

    cv2.imshow('keypoint match', img3)
    cv2.waitKey(1)


    return img3, (kp1, des1, kp2, des2, matches)



# 画像の表示
def display(img, output_file_path):
    cv2.imwrite(output_file_path, img)
    plt.imshow(plt.imread(output_file_path))
    plt.axis('off')
    plt.show()







def crop(image, pt, size):
    """
    画像の一部を矩形で切り取る
    
    Parameters
    ----------
    image : mat
        切り出し元の画像
    pt : [number, number]
        切り取り中心[col, row]
    size : [number, number]
        切り取りサイズ[width, height]

    Returns
    -------
        切り出した画像
    """
    left = int(pt[0] - size[0] / 2)
    if left < 0:
        left = 0      
    right = int(pt[0] + size[0] / 2)
    top = int(pt[1] - size[1] / 2)
    if top < 0:
        top = 0
    bottom = int(pt[1] + size[1] / 2)
    d = len(image.shape)
    if d <= 2:
        #grayscale
        return image[top:bottom, left:right]
    else:
        #color
        return image[top:bottom, left:right, :]



def ocrLcd(image):
    """
    OCRで発光周期時間を読み取り
    
    Parameters
    ----------
    image : mat
        画像
 
    Returns
    -------
        読み取った文字列
    """

    #lcdImage = crop(image, ( 1800, 800) , ( 1000, 1000)) 
    #lcdImage = cv2.convertScaleAbs(lcdImage, alpha = 0.5, beta = -20)
    #lcdImage = cv2.medianBlur(lcdImage, ksize = 1) #ksizeは奇数
    #ret, lcdImage = cv2.threshold(lcdImage, 95, 255,cv2.THRESH_BINARY)

    # 20200717 P110170~
    lcdImage = crop(image, ( 2300, 3000) , ( 1000, 1000))  
    lcdImage = cv2.convertScaleAbs(lcdImage, alpha = 0.5, beta = -20)
    lcdImage = cv2.medianBlur(lcdImage, ksize = 3) #ksizeは奇数
    ret, lcdImage2 = cv2.threshold(lcdImage, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    print('OCR th:', ret)
    ret,lcdImage = cv2.threshold(lcdImage, ret + 35, 255,cv2.THRESH_BINARY)
    #retはOTSUのときのしきい値
    kernel = np.ones((3,3),np.uint8)
    lcdImage = cv2.erode(lcdImage, kernel, 4)

    #lcdImage = rot(lcdImage, 91.5)
    lcdImage = rot(lcdImage, -90)
    #cv2.imshow("image4", lcdImage)
    #cv2.waitKey(1) 
    lcdImage = cv2.bitwise_not(lcdImage)    #反転
    #cv2.imshow("image4", lcdImage)
    #cv2.waitKey(1) 

    #####test 文字
    cv2.putText(lcdImage, "* test 12.3m/sec (456.7us) test *", org = (20, 860), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1.0, color = (0,0,0), thickness = 2)
    cv2.imwrite('ocrimg.png', lcdImage)

    cv2.namedWindow("lcdImage", cv2.WINDOW_NORMAL)
    h = lcdImage.shape[0]
    w = lcdImage.shape[1]
    rLcdImage = cv2.resize(lcdImage, (w // 2, h // 2))

    cv2.imshow("lcdImage", rLcdImage)
    cv2.moveWindow("lcdImage", 0, 500)

    #cv2.imwrite("test.png",lcdImage)
    cv2.waitKey(1) 
    
    tools = pyocr.get_available_tools()
    if len(tools) == 0:
        #print("No OCR tool found")
        SystemExit(1)

    tool = tools[0]
    #print("will use tool '%s'" % (tool.get_name()))
    langs = tool.get_available_languages()
    #print("available languages: %s" % ", ".join(langs))

    #builder = pyocr.builders.TextBuilder(tesseract_layout =  6) #text
    builder = pyocr.builders.WordBoxBuilder(tesseract_layout=6) #box
    txt = tool.image_to_string(Image.open('ocrimg.png'), lang = 'eng', builder = builder)
    
    out = cv2.imread('ocrimg.png')
    for r in txt:
        #print(r.content, end = ' ')
        #print(r.position)
        cv2.rectangle(out, r.position[0], r.position[1],(255, 0, 255), 2)

    cv2.imshow('lcdImage', out)
    cv2.waitKey(1)
    #print(txt)
    #print()

    return txt


def rot(image, degree):
    """
    画像を画像中央を中心に回転させる。回転により生じる背景は白で塗りつぶし。
    
    Parameters
    ----------
    image : mat
        元画像
    degree : float
        回転角度(deg)

    Returns
    -------
    回転した画像
    """
    (h, w) = (0, 0)
    if(len(image.shape)):
        #gray scale
        (h, w) = image.shape
        bg = 255
    else:
        #color
        (h, w) = image.shape[:2]
        bg = (255, 255, 255)
    center = (w / 2.0, h / 2.0)
    mat = cv2.getRotationMatrix2D(center, degree, scale = 1.0)  #回転のための変換行列を生成
    return cv2.warpAffine(image, mat, (w, h), borderValue = bg)     #アフィン変換


def mask_circle(image, dia):
    """
    円形でマスク。

    Parameters
    ----------
    image : mat
        画像
    dia : int
        円の直径(px)

    Returns
    -------
    マスクした画像
    """
    #マスク画像の元を作成（白一面）
    mask = np.full(image.shape[:2], 255, dtype = image.dtype)

    #白い画像の中心に黒い円を描画する。
    centerX = image.shape[1] // 2
    centerY = image.shape[0] // 2
    cv2.circle(mask, (centerX, centerY), (dia // 2), color = 0, thickness = - 1)
    #cv2.imshow('TMask', mask)
    #cv2.waitKey(0)
    return cv2.bitwise_or(image, mask)


def winShow(image, name, pt, size):
    """
    画像をウインドウで表示
    Parameters
    ----------
    image : mat
        画像データ
    name : string
        ウインドウ名
    pt : [number, number]
        ウインドウ表示位置[col, row]pixel
    size : [number, number]
        ウインドウに表示する画像サイズ[width, height]pixel
    Returns
    -------
    なし
    """
    cv2.namedWindow(name, cv2.WINDOW_NORMAL)
    cv2.imshow(name, image)
    cv2.moveWindow(name, pt[0], pt[1])
    cv2.resizeWindow(name, size[0], size[1])
    return



####  main  ######
#指定したフォルダの画像すべてに対して実行
#pythonの関数の定義位置は、実際に実行するまでに定義されていればよい。
#プログラムは先頭から実行されていくがdef関数定義の中身は実行されないので、実際に呼び出された時で考える。
#ここでprocess()が呼ばれるまでにprocess()中で呼ばれる関数は定義されているのでprocess()の後に定義でもオッケー

root = './bbpict/go'
files = os.listdir(path = root)
filesSorted = sorted(files)
filesSorted.remove('.DS_Store')
for f in filesSorted:
    openFileName = os.path.join(root, f)
    print()
    print()
    print('filename = ', openFileName)
    res = process(openFileName)
    savedFileName = "result" + f
    cv2.imwrite(savedFileName, res)

print('Complete')
print('any key -> exit system')
cv2.waitKey(0)


